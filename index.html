<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yogesh Thangamuthu</title>
    <script defer src="script.js"></script>

    <meta name="author" content="Yogesh Thangamuthu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yogesh Thangamuthu
                </p>
                <p>
                  I am fascinated by <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision</a> and its transformative impact on both technology and society. 
                </p>
                <p>I received my undergrads from anna university and <a href='https://drive.google.com/file/d/1JFFbW5IvqEDEXFNcDRoQE03PjrYz1m5x/view?usp=share_link'>Master degree from Aston university </a> in 2021 and 2023 respectively, fortunately supervised by  <span class="highlight">Prof. Philip Trevelyan</span>.
                </p>
                <p>
                  My current research focuses on vision foundation model and vision-language model. Previously, I worked on learning from cheap visual data.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yogeshdataanalystuk@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Yogesh_Thangamuthu.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yoket/">LinkedIN</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Yogeshdataanalytstuk/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/yogi.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/yogi.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Topic's explored </h2>
                <p>
                  
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some experiences are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr onmouseout="lpr_stop()" onmouseover="lpr_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='lprimage'><video  width=100% muted autoplay loop>
                  <source src="images/lpr.gif" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/lpr.gif' width=100%>
                </div>
                <script type="text/javascript">
                  function lpr_start() {
                    document.getElementById('lpr_image').style.opacity = "1";
                  }

                  function lpr_stop() {
                    document.getElementById('lpr_image').style.opacity = "0";
                  }
                  lpr_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/Yogeshdataanalytstuk/d_app_one_cam">
                  <span class="papertitle">ANPR Model: Tracking, OCR, Identification </span>
                </a>
                <br>
            <strong>Yogesh Thangamuthu</strong>
                
                <br>
                <a href="http://app.ndspectra.co.uk/">project page</a>
                /
                <a href="https://adjoining-sun-3e1.notion.site/Licence-Plate-Recogniser-LPR-d7b714d0150d4b9486f72d5f5134868f">blog</a>

                
                <p></p>
                <p>
                  This application harnesses the power of convolutional neural networks (CNNs) to enable real-time tracking and optical character recognition (OCR) of vehicles, leveraging state-of-the-art deep learning techniques for precise vehicle type classification and license plate extraction. The core functionality is powered by PyQt6, which supports sophisticated video analysis, object detection, and model identification workflows. 

        The system further enhances its tracking capabilities through the integration of predictive tracking algorithms that anticipate vehicle movements, improving the accuracy and reliability of the monitoring process. It operates as a web-based platform, engineered using Flask to facilitate user interaction and data handling, with Kafka serving as a high-throughput, fault-tolerant data streaming service to manage the flow of real-time information. 

        Redis is strategically implemented to act as an in-memory data structure store, optimizing the retrieval and management of vehicle data lists, thus reducing latency and increasing the efficiency of data operations. The architecture of the application is meticulously designed to minimize computational load through the use of optimized deep learning models and efficient coding techniques, making it highly suitable for deployment in scenarios where both cost and performance are critical, such as traffic and parking management systems and security infrastructure.
                </p>
              </td>
            </tr>
            
            <tr onmouseout="bird_stop()" onmouseover="bird_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='birdimage'><video  width=100% muted autoplay loop>
                  <source src="images/bird.JPG" >
                  Your browser does not support the image tag.
                  </video></div>
                  <img src='images/bird.JPG' width=100%>
                </div>
                <script type="text/javascript">
                  function bird_start() {
                    document.getElementById('bird_image').style.opacity = "1";
                  }

                  function bird_stop() {
                    document.getElementById('bird_image').style.opacity = "0";
                  }
                  bird_stop()
                </script>
                        <p>&nbsp;</p>

                        <p>&nbsp;</p>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="">
                  <span class="papertitle">Deep Learning-Based Bird Detection for Airport Runways </span>
                </a>
                <br>
            <strong>Yogesh Thangamuthu</strong>
                
                <br>
                <a href="https://en.wikipedia.org/wiki/INS_Parundu">Indian navy </a>
                /
                <a href="https://www.notion.so/Bird-Analytics-Application-Documentation-fe3e65532dfc4e7b90761cb832006a43?pvs=4">blog</a>
                
                <p>


                </p>
                <p>


                </p>
                <p>

                  
                </p>
                <p>
                  Utilizing IP cameras and deep learning for bird movement analysis, featuring PyQt security and on-premise dashboard analytics.
                </p>


              </td>
            </tr>

    
            
          </tbody></table>

            <h2>Learning in Action</h2>
            <p class="expand-note">*Click the topic to expand.</p>
            <div class="grid-container">
              <div class="grid-item">
                <h3>Depth Analysing</h3>
                
                <p>&nbsp;</p>
                <a href="https://github.com/DepthAnything">Inspired from DepthAnything </a>
                <p class="description">
                  Machine learning enhances object detection with depth images by extracting relevant 3D features, reducing false positives, and filtering noise. It enables robust, light-independent detection by training on large datasets and fusing RGB and depth data for improved accuracy in complex environments .<span class="highlight">Image is generted using depth anything v-2</span>.
                  <img src="images/car-3d.gif" alt="GIF " class="description-gif">
                  
                </p>
              </div>
              <div class="grid-item">
                <h3>Impact assessment</h3>
                <p>&nbsp;</p>
                
                <p class="description">
                  Leveraging deep learning algorithms on images and video for vehicle damage assessment automates the detection, segmentation, and quantification of damage. This approach enhances accuracy, speed, and scalability, while integrating cost estimation and claims detection models to streamline the automotive insurance industry with precise, efficient, and cost-effective claims evaluation.
                  <img src="images/car-damage.png" alt="GIF " class="description-gif">
                </p>
              </div>
              <div class="grid-item">
                <h3>3D Rendering</h3>
                <p>&nbsp;</p>
                
                <p class="description">
                  Passionate about exploring the intersection of Neural Radiance Fields <span class="highlight">(NeRF)</span> and 3D rendering. Committed to mastering advanced visualization techniques to push the boundaries of virtual and augmented reality.
                  <img src="images/image-rendering.png" alt="GIF " class="description-gif">
                </p>
              </div>
              
              
            </div>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design and source code from <a href="https://jonbarron.info">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>


        
          
          
      
    </table>
  </body>
</html>
